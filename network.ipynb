{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq3brxWtBYG0"
      },
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82X1bkDBjpe"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCN\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms2U5wVrBo2u"
      },
      "source": [
        "nx_graph = nx.read_gml('graph_with_features.gml')\n",
        "G = from_networkx(nx_graph, group_node_attrs=['out_degree', 'in_degree', 'category_multi_hot'], group_edge_attrs=['tf_idf', 'num_link_clicked'])\n",
        "\n",
        "path_data = pd.read_csv('data_by_index.tsv', sep='\\t', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t96m5KPgYZEF"
      },
      "source": [
        "class CustomPathDataset(Dataset):\n",
        "    def __init__(self, path_data):\n",
        "        self.x = path_data[0].apply(json.loads)\n",
        "        self.labels = path_data[1]\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.LongTensor(self.x[idx])\n",
        "        label = self.labels[idx]\n",
        "        sample = {\"indices\": x, \"label\": label}\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHTFTfi9MqGi"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, graph, gnn_hidden_size=128, node_embed_size=64, lstm_hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.graph = graph\n",
        "        # self.edge_feat = TODO: add node features\n",
        "        self.gcn = GCN(in_channels=self.graph.x.shape[1], \n",
        "                       hidden_channels=gnn_hidden_size, \n",
        "                       num_layers=3, \n",
        "                       out_channels=node_embed_size, \n",
        "                       dropout=0.1)\n",
        "        self.lstm_input_size = node_embed_size # TODO: replace with line below when adding edge features\n",
        "        # self.lstm_input_size = node_embed_size + 2\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_size,\n",
        "                            hidden_size=lstm_hidden_size,\n",
        "                            batch_first=True)\n",
        "        self.pred_head = nn.Linear(lstm_hidden_size, self.graph.x.shape[0])\n",
        "\n",
        "    def forward(self, indices):\n",
        "        node_emb = self.gcn(self.graph.x, self.graph.edge_index)\n",
        "        node_emb_with_padding = torch.cat([node_emb, torch.zeros((1, self.lstm_input_size))])\n",
        "        paths = node_emb_with_padding[indices] # TODO: need to append edge features to data before passing into LSTM\n",
        "        out, _ = self.lstm(paths)\n",
        "        predictions = self.pred_head(torch.sum(out, dim=1))\n",
        "        return F.log_softmax(predictions, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBksmbZ7QPBg"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(G).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "dataset = CustomPathDataset(path_data)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data['indices'], data['label']\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = F.nll_loss(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        print('Epoch:', epoch)\n",
        "        print('Loss:', loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4GmtmI1V18K"
      },
      "source": [
        "test_inputs = None\n",
        "test_labels = None\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "model.eval()\n",
        "num_correct = 0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data['indices'], data['label']\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      pred = model(outputs).argmax(dim=1)\n",
        "      correct = (pred == label).sum()\n",
        "      num_correct += correct\n",
        "\n",
        "acc = int(correct) / int(len(pred))\n",
        "print(f'Accuracy: {acc:.4f}')\n",
        "\n",
        "      # print statistics\n",
        "      print('Epoch:', epoch)\n",
        "      print('Loss:', loss)\n",
        "\n",
        "pred = model(test_inputs).argmax(dim=1)\n",
        "correct = (pred == torch.zeros_like(pred)).sum()\n",
        "acc = int(correct) / int(len(pred))\n",
        "print(f'Accuracy: {acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}